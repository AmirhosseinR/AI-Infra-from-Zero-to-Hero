- PaGraph: Scaling GNN training on large graphs via computation-aware caching
  - 本文章主要针对大规模GNN训练。当前方案用mini-batch和sampling，在大的graph上进行训练。
  - 但是在从CPU载入rich vertices到GPU的时候，他们会有scalability的问题，此时bandwidth极大地限制了训练。
  - 这篇文章提出了一个系统，在单机多卡上面训练GNN。他利用可用GPU资源作为缓存载体，减少data loading time。他们还设计了一个缓存策略，考虑图结构信息和数据获取模式。最后，为了在多个GPU上面分布式计算，他们开发了一个fast GNN-computation-aware partition algorithm来减少交叉切割。
  
- Baechi: fast device placement of machine learning graphs 
  - 这个文章应该是follow google那个DRL文章，做device placement。
  - 之前的方案会导致训练model-parallelism非常耗时，因为规划算子在不同device这个过程很花时间。
  - 这个文章提出了一个系统，可以再资源受限的小集群上面运行。系统中包含了一个高效算法，可以极大地加速方案搜索。

- Semi-dynamic load balancing: efficient distributed learning in non-dedicated environments (HKUST)
  - 在集群上训练深度学习模型，经常会遇到非独占的并且异构的资源。这会导致分布式训练被其中较慢的设备所限制，导致效率降低。
  - 目前的load balancer无法高效可行的解决这个问题。
  - 所以，这个文章就设计了一个半动态的load balancer解决这个问题，主要思想就是在以每次training interation为界限，利用机器当前的瞬时处理能力，及时调整batch size
  
- Network-accelerated distributed machine learning for multi-tenant settings (Uber, AWS, University of Wisconsin-Madison)
  - 在集群中训练中的资源争抢会导致出现straggler（和上面文章类似）
  - 提出了一个统一的网络管理器，MLfabric，来解决这个问题
  - 梯度传输和模型传输这些需要占用大量网络资源的任务，会被统一的进行排队管理，加快收敛，提高效率。同时还会：1）找机会利用空闲机器进行数据集成和分析，2）生成复制体，提高系统对错误的容忍度
  
- Vessels: Efficient and Scalable Deep Learning Prediction on Trusted Processors (Purdue)
  - 这篇文章主要是讲在深度学习系统中进行敏感数据保护 （不是很懂该领域）
  - 先是分析了Intel SGX两个显著问题：需要分配大内存和很低的内存复用率
  - 为了解决这个问题，提出了一个新系统，来做内存优化。具体就是识别分析深度学习程序的内存的分配和利用模式，然后创建一个可信环境，利用较少的资源分配和较高的复用来执行程序
  
- **InferLine: latency-aware provisioning and scaling for prediction serving pipelines (UCB clipper团队续作）**
  - 这篇文章聚焦于机器学习推理pipeline优化
  - 为了保证整个推理流程端到端的延迟，必须要充分的考虑模型的batch size，hardware的类型和动态的arrival rate
  - 文章提出了一个infereline推理系统，来进行资源配给和推理各阶段（pre，inference，...）管理。具体来说就是设计了一个低频使用的组合planer+一个高频的autoscaling tuner。前者对每个阶段进行性能分析和摩西，然后自动的选择hardware，batch size还有扩容数的组合。后者对每个阶段利用网络积分进行分析（不是很懂，看一下细节需要），然后自动化按照阶段以及arrival rate进行扩容
